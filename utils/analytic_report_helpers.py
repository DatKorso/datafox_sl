"""
Helper functions for analytic report processing.

This module provides functionality to:
- Load and validate analytic report Excel files
- Map WB SKUs to Ozon SKUs by sizes
- Calculate size ranges and stock aggregations
- Generate order statistics for analytic reports
- Update Excel files with calculated data while preserving structure
"""
import pandas as pd
import openpyxl
from openpyxl import load_workbook
from openpyxl.drawing.image import Image
import os
from datetime import datetime, timedelta
import streamlit as st
from typing import Dict, List, Tuple, Optional
import requests
from io import BytesIO
import tempfile
from PIL import Image as PILImage
from utils.db_search_helpers import get_normalized_wb_barcodes, get_ozon_barcodes_and_identifiers

def load_analytic_report_file(file_path: str) -> Tuple[Optional[pd.DataFrame], Optional[openpyxl.Workbook], str]:
    """
    Loads and validates an analytic report Excel file.
    
    Args:
        file_path: Path to the Excel file
        
    Returns:
        Tuple of (DataFrame with data from row 9+, Workbook object, error message if any)
    """
    if not os.path.exists(file_path):
        return None, None, f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}"
    
    try:
        # Load workbook to check structure
        wb = load_workbook(file_path)
        
        if "analytic_report" not in wb.sheetnames:
            return None, None, "–õ–∏—Å—Ç 'analytic_report' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ñ–∞–π–ª–µ"
        
        ws = wb["analytic_report"]
        
        # Check if there are at least 9 rows
        if ws.max_row < 9:
            return None, None, "–í —Ñ–∞–π–ª–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å—Ç—Ä–æ–∫. –û–∂–∏–¥–∞–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 9 —Å—Ç—Ä–æ–∫"
        
        # Load data starting from row 9 (index 8 in pandas)
        df = pd.read_excel(file_path, sheet_name="analytic_report", header=6, skiprows=[7])
        
        # Check if WB_SKU column exists
        if "WB_SKU" not in df.columns:
            return None, None, "–ö–æ–ª–æ–Ω–∫–∞ 'WB_SKU' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ 7-–π —Å—Ç—Ä–æ–∫–µ —Ñ–∞–π–ª–∞"
        
        # Remove empty rows
        df = df.dropna(subset=["WB_SKU"])
        
        if df.empty:
            return None, None, "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö —Å WB_SKU –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"
        
        return df, wb, ""
        
    except Exception as e:
        return None, None, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {str(e)}"

def map_wb_to_ozon_by_size(db_conn, wb_sku_list: List[str]) -> Dict[str, Dict[int, List[str]]]:
    """
    Maps WB SKUs to Ozon SKUs grouped by sizes.
    Uses wb_products.wb_size to determine size and maps through common barcodes.
    
    –û–ë–ù–û–í–õ–ï–ù–û: –¢–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π CrossMarketplaceLinker
    –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –ª–æ–≥–∏–∫–∏ —Å–≤—è–∑—ã–≤–∞–Ω–∏—è.
    
    Args:
        db_conn: Database connection
        wb_sku_list: List of WB SKUs to process
        
    Returns:
        Dict mapping wb_sku -> size -> [list of oz_skus]
    """
    if not wb_sku_list:
        return {}
    
    try:
        # Use centralized linker for WB-Ozon links grouped by sizes
        from utils.cross_marketplace_linker import CrossMarketplaceLinker
        linker = CrossMarketplaceLinker(db_conn)
        
        return linker.get_links_with_sizes(wb_sku_list)
        
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏ WB –∏ Ozon —Ä–∞–∑–º–µ—Ä–æ–≤: {e}")
        return {}

def calculate_size_range(size_mapping: Dict[int, List[str]]) -> str:
    """
    Calculates size range string from size mapping.
    
    Args:
        size_mapping: Dict mapping size -> [list of oz_skus]
        
    Returns:
        Size range string like "27-38" or empty string if no sizes
    """
    sizes_with_skus = [size for size, skus in size_mapping.items() if skus]
    
    if not sizes_with_skus:
        return ""
    
    min_size = min(sizes_with_skus)
    max_size = max(sizes_with_skus)
    
    if min_size == max_size:
        return str(min_size)
    else:
        return f"{min_size}-{max_size}"

def aggregate_stock_data(db_conn, oz_sku_list: List[str]) -> int:
    """
    Aggregates stock data for a list of Ozon SKUs.
    
    Args:
        db_conn: Database connection
        oz_sku_list: List of Ozon SKUs
        
    Returns:
        Total stock amount
    """
    if not oz_sku_list:
        return 0
    
    try:
        stock_query = f"""
        SELECT COALESCE(SUM(oz_fbo_stock), 0) as total_stock
        FROM oz_products 
        WHERE oz_sku IN ({', '.join(['?'] * len(oz_sku_list))})
        """
        result = db_conn.execute(stock_query, oz_sku_list).fetchdf()
        return int(result.iloc[0]['total_stock']) if not result.empty else 0
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –æ –æ—Å—Ç–∞—Ç–∫–∞—Ö: {e}")
        return 0

def generate_order_statistics(db_conn, oz_sku_list: List[str], days_back: int = 30) -> Dict[str, int]:
    """
    Generates order statistics for Ozon SKUs for the last N days.
    
    Args:
        db_conn: Database connection
        oz_sku_list: List of Ozon SKUs
        days_back: Number of days to look back
        
    Returns:
        Dict mapping date_string (YYYY-MM-DD) -> order_count
    """
    if not oz_sku_list:
        return {}
    
    try:
        today = datetime.now()
        start_date = (today - timedelta(days=days_back)).strftime('%Y-%m-%d')
        
        orders_query = f"""
        SELECT 
            oz_accepted_date,
            COUNT(*) as order_count
        FROM oz_orders
        WHERE oz_sku IN ({', '.join(['?'] * len(oz_sku_list))})
            AND oz_accepted_date >= ?
            AND order_status != '–û—Ç–º–µ–Ω—ë–Ω'
        GROUP BY oz_accepted_date
        ORDER BY oz_accepted_date DESC
        """
        
        orders_df = db_conn.execute(orders_query, oz_sku_list + [start_date]).fetchdf()
        
        if orders_df.empty:
            return {}
        
        # Convert to dict
        orders_df['oz_accepted_date'] = pd.to_datetime(orders_df['oz_accepted_date']).dt.strftime('%Y-%m-%d')
        return dict(zip(orders_df['oz_accepted_date'], orders_df['order_count']))
        
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞–∫–∞–∑–æ–≤: {e}")
        return {}

def create_backup_file(file_path: str) -> str:
    """
    Creates a backup of the original file with timestamp.
    
    Args:
        file_path: Path to the original file
        
    Returns:
        Path to the backup file
    """
    directory = os.path.dirname(file_path)
    filename = os.path.basename(file_path)
    name, ext = os.path.splitext(filename)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_filename = f"{name}_backup_{timestamp}{ext}"
    backup_path = os.path.join(directory, backup_filename)
    
    # Copy the file
    import shutil
    shutil.copy2(file_path, backup_path)
    
    return backup_path

def get_wb_image_url(wb_sku: str) -> str:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è WB –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞—Ä—Ç–∏–∫—É–ª–∞.
    –†–µ–∞–ª–∏–∑—É–µ—Ç –∞–ª–≥–æ—Ä–∏—Ç–º –∏–∑ Google Sheets –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ URL.
    
    Args:
        wb_sku: –ê—Ä—Ç–∏–∫—É–ª WB (—Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ —á–∏—Å–ª–æ)
        
    Returns:
        URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å
    """
    try:
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ
        a = int(float(wb_sku))
        
        # –í—ã—á–∏—Å–ª—è–µ–º b –∏ c
        b = a // 100000
        c = a // 1000
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º volNum –ø–æ –∞–ª–≥–æ—Ä–∏—Ç–º—É –∏–∑ Google Sheets
        if b <= 143:
            vol_num = "01"
        elif b <= 287:
            vol_num = "02"
        elif b <= 431:
            vol_num = "03"
        elif b <= 719:
            vol_num = "04"
        elif b <= 1007:
            vol_num = "05"
        elif b <= 1061:
            vol_num = "06"
        elif b <= 1115:
            vol_num = "07"
        elif b <= 1169:
            vol_num = "08"
        elif b <= 1313:
            vol_num = "09"
        elif b <= 1601:
            vol_num = "10"
        elif b <= 1655:
            vol_num = "11"
        elif b <= 1919:
            vol_num = "12"
        elif b <= 2045:
            vol_num = "13"
        elif b <= 2189:
            vol_num = "14"
        elif b <= 2405:
            vol_num = "15"
        elif b <= 2621:
            vol_num = "16"
        elif b <= 2837:
            vol_num = "17"
        elif b <= 3053:
            vol_num = "18"
        elif b <= 3269:
            vol_num = "19"
        elif b <= 3485:
            vol_num = "20"
        elif b <= 3701:
            vol_num = "21"
        elif b <= 3917:
            vol_num = "22"
        elif b <= 4133:
            vol_num = "23"
        elif b <= 4349:
            vol_num = "24"
        else:
            vol_num = "25"
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º URL
        image_url = f"https://basket-{vol_num}.wbbasket.ru/vol{b}/part{c}/{a}/images/tm/1.webp"
        return image_url
        
    except (ValueError, TypeError) as e:
        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è WB_SKU {wb_sku}: {e}")
        return ""

def download_wb_image(wb_sku: str, timeout: int = 30) -> Optional[BytesIO]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ WB –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É.
    
    Args:
        wb_sku: –ê—Ä—Ç–∏–∫—É–ª WB
        timeout: –¢–∞–π–º–∞—É—Ç –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        
    Returns:
        BytesIO –æ–±—ä–µ–∫—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –∏–ª–∏ None –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å
    """
    image_url = get_wb_image_url(wb_sku)
    if not image_url:
        return None
    
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º headers —á—Ç–æ–±—ã –∏–º–∏—Ç–∏—Ä–æ–≤–∞—Ç—å –±—Ä–∞—É–∑–µ—Ä
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'image/webp,image/apng,image/*,*/*;q=0.8',
            'Accept-Language': 'ru-RU,ru;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }
        
        response = requests.get(image_url, timeout=timeout, headers=headers)
        response.raise_for_status()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        content_type = response.headers.get('content-type', '')
        if not content_type.startswith('image/'):
            st.warning(f"URL –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è WB_SKU {wb_sku}: {content_type}")
            return None
        
        return BytesIO(response.content)
        
    except requests.exceptions.RequestException as e:
        st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è WB_SKU {wb_sku}: {e}")
        return None
    except Exception as e:
        st.warning(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è WB_SKU {wb_sku}: {e}")
        return None

def insert_wb_image_to_cell(ws, row_num: int, col_num: int, wb_sku: str, cell_width: float = 64, cell_height: float = 64) -> Tuple[bool, Optional[str]]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –≤—Å—Ç–∞–≤–ª—è–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ WB –≤ —è—á–µ–π–∫—É Excel.
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç WebP –≤ PNG –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å Excel.
    –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫ —è—á–µ–π–∫–µ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Ä–∞–∑–º–µ—Ä–æ–≤.
    
    Args:
        ws: Worksheet –æ–±—ä–µ–∫—Ç openpyxl
        row_num: –ù–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏
        col_num: –ù–æ–º–µ—Ä –∫–æ–ª–æ–Ω–∫–∏
        wb_sku: –ê—Ä—Ç–∏–∫—É–ª WB
        cell_width: –®–∏—Ä–∏–Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ø–∏–∫—Å–µ–ª—è—Ö
        cell_height: –í—ã—Å–æ—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ø–∏–∫—Å–µ–ª—è—Ö
        
    Returns:
        Tuple: (—É—Å–ø–µ—Ö, –ø—É—Ç—å_–∫_–≤—Ä–µ–º–µ–Ω–Ω–æ–º—É_—Ñ–∞–π–ª—É_–¥–ª—è_–æ—á–∏—Å—Ç–∫–∏)
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ –≤—Ä–µ–º–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É, –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å –ø–æ–∑–∂–µ
    """
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image_data = download_wb_image(wb_sku)
        if not image_data:
            return False, None
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ PNG
        try:
            temp_file = tempfile.NamedTemporaryFile(suffix='.png', delete=False)
            temp_file_path = temp_file.name
            temp_file.close()  # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª –¥–ª—è –∑–∞–ø–∏—Å–∏ —á–µ—Ä–µ–∑ PIL
            
            # –û—Ç–∫—Ä—ã–≤–∞–µ–º WebP –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ BytesIO
            image_data.seek(0)
            pil_image = PILImage.open(image_data)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ (–¥–ª—è PNG)
            if pil_image.mode in ("RGBA", "P"):
                pil_image = pil_image.convert("RGB")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ PNG
            pil_image.save(temp_file_path, "PNG")
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            if not os.path.exists(temp_file_path):
                st.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è WB_SKU {wb_sku}")
                return False, None
            
        except Exception as temp_error:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è WB_SKU {wb_sku}: {temp_error}")
            return False, None
        
        try:
            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è openpyxl
            img = Image(temp_file_path)
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            img.width = cell_width
            img.height = cell_height
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —è—á–µ–π–∫–∏
            from openpyxl.utils import get_column_letter
            cell_address = f"{get_column_letter(col_num)}{row_num}"
            
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø—Ä–∏–≤—è–∑–∫—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫ —è—á–µ–π–∫–µ
            # –≠—Ç–æ –∑–∞—Å—Ç–∞–≤–ª—è–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–≤–∏–≥–∞—Ç—å—Å—è –∏ –∏–∑–º–µ–Ω—è—Ç—å—Å—è –≤–º–µ—Å—Ç–µ —Å —è—á–µ–π–∫–æ–π
            img.anchor = cell_address
            
            # –í—Å—Ç–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —è—á–µ–π–∫—É (–±–µ–∑ —Ç–µ–∫—Å—Ç–∞)
            ws.add_image(img, cell_address)
            
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —Å—Ç—Ä–æ–∫–∏ –∏ —Å—Ç–æ–ª–±—Ü–∞ —á—Ç–æ–±—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–º–µ—â–∞–ª–æ—Å—å
            ws.row_dimensions[row_num].height = max(ws.row_dimensions[row_num].height or 15, cell_height * 0.75)
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —à–∏—Ä–∏–Ω—É —Å—Ç–æ–ª–±—Ü–∞ –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
            column_letter = get_column_letter(col_num)
            current_width = ws.column_dimensions[column_letter].width
            if current_width is None or current_width < (cell_width / 7):  # –ü—Ä–∏–º–µ—Ä–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –ø–∏–∫—Å–µ–ª–µ–π –∫ Excel –µ–¥–∏–Ω–∏—Ü–∞–º
                ws.column_dimensions[column_letter].width = cell_width / 7
            
            # –û—Å—Ç–∞–≤–ª—è–µ–º —è—á–µ–π–∫—É –ø—É—Å—Ç–æ–π (–±–µ–∑ —Ç–µ–∫—Å—Ç–∞ –≥–∏–ø–µ—Ä—Å—Å—ã–ª–∫–∏)
            # –ï—Å–ª–∏ –Ω—É–∂–Ω–∞ –≥–∏–ø–µ—Ä—Å—Å—ã–ª–∫–∞, –µ—ë –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —á–µ—Ä–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
            
            return True, temp_file_path
            
        except Exception as e_insert:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—Å—Ç–∞–≤–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è WB_SKU {wb_sku}: {e_insert}")
            # –ï—Å–ª–∏ –≤—Å—Ç–∞–≤–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å, —É–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å—Ä–∞–∑—É
            try:
                if os.path.exists(temp_file_path):
                    os.unlink(temp_file_path)
            except Exception as cleanup_error:
                pass  # –¢–∏—Ö–æ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –æ—á–∏—Å—Ç–∫–∏
            raise e_insert
                
    except Exception as e:
        st.error(f"‚ùå –û–±—â–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è WB_SKU {wb_sku}: {e}")
        return False, None

def update_analytic_report(file_path: str, wb_sku_data: Dict[str, Dict], include_images: bool = False) -> Tuple[bool, str]:
    """
    Updates the analytic report Excel file with calculated data.
    Now includes support for PHOTO_FROM_WB column with image insertion.
    
    Args:
        file_path: Path to the Excel file
        wb_sku_data: Dict containing calculated data for each WB SKU
        include_images: Whether to download and insert product images from WB
        
    Returns:
        Tuple of (success, error_message)
    """
    temp_image_files = []  # –°–ø–∏—Å–æ–∫ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
    
    try:
        # Create backup only for non-temporary files
        backup_created = False
        if not os.path.basename(file_path).startswith('temp_'):
            backup_path = create_backup_file(file_path)
            st.info(f"–°–æ–∑–¥–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: {os.path.basename(backup_path)}")
            backup_created = True
        
        # Load workbook
        wb = load_workbook(file_path)
        ws = wb["analytic_report"]
        
        # Find column indices from row 7 (header row)
        header_row = 7
        column_map = {}
        
        for col_num in range(1, ws.max_column + 1):
            cell_value = ws.cell(row=header_row, column=col_num).value
            if cell_value:
                column_map[str(cell_value).strip()] = col_num
        
        # Check if PHOTO_FROM_WB column exists and images are enabled
        has_photo_column = "PHOTO_FROM_WB" in column_map and include_images
        if "PHOTO_FROM_WB" in column_map:
            if include_images:
                st.info("üñºÔ∏è –ù–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ PHOTO_FROM_WB - –±—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤")
            else:
                st.info("üì∑ –ù–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ PHOTO_FROM_WB - –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –æ—Ç–∫–ª—é—á–µ–Ω–æ (—è—á–µ–π–∫–∏ –æ—Å—Ç–∞–Ω—É—Ç—Å—è –ø—É—Å—Ç—ã–º–∏)")
        
        # Process data starting from row 9
        data_start_row = 9
        photo_success_count = 0
        photo_total_count = 0
        failed_images = []  # –°–ø–∏—Å–æ–∫ –Ω–µ—É–¥–∞—á–Ω—ã—Ö –∑–∞–≥—Ä—É–∑–æ–∫ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ª–æ–≥–∞
        
        # Collect all WB SKUs for batch processing info
        wb_skus_to_process = []
        for row_num in range(data_start_row, ws.max_row + 1):
            wb_sku_cell = ws.cell(row=row_num, column=column_map.get("WB_SKU", 2))
            wb_sku = str(wb_sku_cell.value).strip() if wb_sku_cell.value else ""
            if wb_sku and wb_sku in wb_sku_data:
                wb_skus_to_process.append((row_num, wb_sku))
        
        # Show compact processing info
        if has_photo_column and wb_skus_to_process:
            st.info(f"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(wb_skus_to_process)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤...")
        
        # Process each row
        for row_num, wb_sku in wb_skus_to_process:
            data = wb_sku_data[wb_sku]
            
            # Update size columns (OZ_SIZE_22 to OZ_SIZE_44)
            for size in range(22, 45):
                col_name = f"OZ_SIZE_{size}"
                if col_name in column_map:
                    col_num = column_map[col_name]
                    oz_skus = data.get('sizes', {}).get(size, [])
                    ws.cell(row=row_num, column=col_num).value = ';'.join(oz_skus) if oz_skus else ""
            
            # Update OZ_SIZES
            if "OZ_SIZES" in column_map:
                ws.cell(row=row_num, column=column_map["OZ_SIZES"]).value = data.get('size_range', '')
            
            # Update OZ_STOCK
            if "OZ_STOCK" in column_map:
                ws.cell(row=row_num, column=column_map["OZ_STOCK"]).value = data.get('total_stock', 0)
            
            # Update order statistics columns (ORDERS_TODAY-30 to ORDERS_TODAY-1)
            orders_data = data.get('orders', {})
            today = datetime.now()
            for days_back in range(1, 31):
                col_name = f"ORDERS_TODAY-{days_back}"
                if col_name in column_map:
                    target_date = (today - timedelta(days=days_back)).strftime('%Y-%m-%d')
                    order_count = orders_data.get(target_date, 0)
                    ws.cell(row=row_num, column=column_map[col_name]).value = order_count
            
            # Insert WB image if PHOTO_FROM_WB column exists
            if has_photo_column:
                photo_total_count += 1
                col_num = column_map["PHOTO_FROM_WB"]
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º URL –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                image_url = get_wb_image_url(wb_sku)
                
                if image_url:
                    # –ù–µ –¥–æ–±–∞–≤–ª—è–µ–º –Ω–∏–∫–∞–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –≤ —è—á–µ–π–∫—É - —Ç–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    
                    # –ü—ã—Ç–∞–µ–º—Å—è –≤—Å—Ç–∞–≤–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    try:
                        success, temp_file_path = insert_wb_image_to_cell(ws, row_num, col_num, wb_sku)
                        if success:
                            photo_success_count += 1
                            if temp_file_path:
                                temp_image_files.append(temp_file_path)
                        else:
                            failed_images.append(f"WB_SKU {wb_sku} (—Å—Ç—Ä–æ–∫–∞ {row_num}): –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
                    except Exception as image_error:
                        failed_images.append(f"WB_SKU {wb_sku} (—Å—Ç—Ä–æ–∫–∞ {row_num}): {str(image_error)}")
                else:
                    failed_images.append(f"WB_SKU {wb_sku} (—Å—Ç—Ä–æ–∫–∞ {row_num}): –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å URL")
        
        # Update all PUNTA_ columns dynamically
        punta_columns = {col_name: col_num for col_name, col_num in column_map.items() 
                         if col_name.startswith('PUNTA_')}
        if punta_columns:
            st.info(f"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ {len(punta_columns)} PUNTA_ –∫–æ–ª–æ–Ω–æ–∫: {', '.join(punta_columns.keys())}")
        
        update_punta_columns_dynamically(ws, column_map, wb_sku_data, data_start_row)
        
        # Save the updated file
        wb.save(file_path)
        
        # Show compact image loading statistics
        if has_photo_column and photo_total_count > 0:
            if photo_success_count == photo_total_count:
                st.success(f"üñºÔ∏è –í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ: {photo_success_count} –∏–∑ {photo_total_count}")
            else:
                st.warning(f"üñºÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {photo_success_count} –∏–∑ {photo_total_count} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
                
                # Show failed images in expander
                if failed_images:
                    with st.expander(f"‚ùå –î–µ—Ç–∞–ª–∏ –Ω–µ—É–¥–∞—á–Ω—ã—Ö –∑–∞–≥—Ä—É–∑–æ–∫ ({len(failed_images)})", expanded=False):
                        for error in failed_images:
                            st.text(f"‚Ä¢ {error}")
        
        return True, ""
        
    except Exception as e:
        return False, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {str(e)}"
    
    finally:
        # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ—Å–ª–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        if temp_image_files:
            cleaned_count = 0
            cleanup_errors = []
            
            for temp_file_path in temp_image_files:
                try:
                    if os.path.exists(temp_file_path):
                        os.unlink(temp_file_path)
                        cleaned_count += 1
                    else:
                        cleanup_errors.append(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {os.path.basename(temp_file_path)}")
                except Exception as cleanup_error:
                    cleanup_errors.append(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è {os.path.basename(temp_file_path)}: {cleanup_error}")
            
            # –ö–æ–º–ø–∞–∫—Ç–Ω—ã–π –æ—Ç—á–µ—Ç –æ–± –æ—á–∏—Å—Ç–∫–µ
            if cleaned_count == len(temp_image_files):
                st.info(f"üßπ –û—á–∏—â–µ–Ω–æ {cleaned_count} –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤")
            else:
                st.warning(f"üßπ –û—á–∏—â–µ–Ω–æ {cleaned_count} –∏–∑ {len(temp_image_files)} –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—à–∏–±–∫–∏ –æ—á–∏—Å—Ç–∫–∏ –≤ —Å–ø–æ–π–ª–µ—Ä–µ
                if cleanup_errors:
                    with st.expander(f"‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º—ã –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ ({len(cleanup_errors)})", expanded=False):
                        for error in cleanup_errors:
                            st.text(f"‚Ä¢ {error}")
        # –ï—Å–ª–∏ –Ω–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤, –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–∏—á–µ–≥–æ (—É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–π –ª–æ–≥)

def process_analytic_report(db_conn, file_path: str, include_images: bool = False) -> Tuple[bool, str, Dict]:
    """
    Main function to process the entire analytic report.
    
    Args:
        db_conn: Database connection
        file_path: Path to the Excel file
        include_images: Whether to download and insert product images from WB
        
    Returns:
        Tuple of (success, error_message, statistics_dict)
    """
    # Load and validate file
    df, wb, error_msg = load_analytic_report_file(file_path)
    if df is None:
        return False, error_msg, {}
    
    wb_sku_list = [str(sku) for sku in df['WB_SKU'].dropna().unique()]
    
    if not wb_sku_list:
        return False, "–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö WB SKU –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏", {}
    
    # Process each WB SKU
    wb_sku_data = {}
    
    # Get size mappings for all WB SKUs at once
    size_mappings = map_wb_to_ozon_by_size(db_conn, wb_sku_list)
    
    # Get Punta data for all WB SKUs at once
    punta_mappings = get_punta_data(db_conn, wb_sku_list)
    
    for wb_sku in wb_sku_list:
        size_mapping = size_mappings.get(wb_sku, {})
        
        # Get all oz_skus for this wb_sku
        all_oz_skus = []
        for oz_skus_list in size_mapping.values():
            all_oz_skus.extend(oz_skus_list)
        
        # Calculate size range
        size_range = calculate_size_range(size_mapping)
        
        # Get stock data
        total_stock = aggregate_stock_data(db_conn, all_oz_skus)
        
        # Get order statistics
        orders_data = generate_order_statistics(db_conn, all_oz_skus, days_back=30)
        
        # Get Punta data
        punta_data = punta_mappings.get(wb_sku, {})
        
        wb_sku_data[wb_sku] = {
            'sizes': size_mapping,
            'size_range': size_range,
            'total_stock': total_stock,
            'orders': orders_data,
            'punta': punta_data
        }
    
    # Update the file
    success, error_msg = update_analytic_report(file_path, wb_sku_data, include_images)
    
    if success:
        stats = {
            'processed_wb_skus': len(wb_sku_list),
            'wb_skus_with_ozon_matches': len([wb for wb, data in wb_sku_data.items() if data['sizes']]),
            'total_ozon_skus_found': sum(len([sku for skus_list in data['sizes'].values() for sku in skus_list]) for data in wb_sku_data.values()),
            'total_stock': sum(data['total_stock'] for data in wb_sku_data.values()),
            'wb_skus_with_punta_data': len([wb for wb, data in wb_sku_data.items() if any(data['punta'].values())])
        }
        return True, "", stats
    else:
        return False, error_msg, {}

def get_punta_data(db_conn, wb_sku_list: List[str]) -> Dict[str, Dict[str, str]]:
    """
    Retrieves Punta data for given WB SKUs.
    Now works with dynamic punta_table schema - automatically detects available columns.
    Takes FIRST occurrence for each wb_sku (most actual data) and formats values properly for Excel.
    
    Args:
        db_conn: Database connection
        wb_sku_list: List of WB SKUs to fetch data for
        
    Returns:
        Dict mapping wb_sku -> {column_name: value}
    """
    if not wb_sku_list:
        return {}
    
    try:
        # Import the new function to get dynamic columns
        from .db_crud import get_punta_table_columns
        
        # Get all available columns dynamically
        available_columns = get_punta_table_columns(db_conn)
        
        if not available_columns:
            st.info("üìã –¢–∞–±–ª–∏—Ü–∞ punta_table –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –ø—É—Å—Ç–∞")
            return {}
        
        # Remove wb_sku from list of data columns (it's the key column)
        data_columns = [col for col in available_columns if col != 'wb_sku']
        
        if not data_columns:
            st.warning("‚ö†Ô∏è –í —Ç–∞–±–ª–∏—Ü–µ punta_table –Ω–µ—Ç –∫–æ–ª–æ–Ω–æ–∫ –¥–∞–Ω–Ω—ã—Ö (—Ç–æ–ª—å–∫–æ wb_sku)")
            return {}
        
        st.info(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(data_columns)} –∫–æ–ª–æ–Ω–æ–∫ –≤ punta_table: {', '.join(data_columns)}")
        
        # Convert wb_sku_list to integers for proper matching with punta_table
        wb_skus_int = []
        for wb_sku in wb_sku_list:
            try:
                wb_skus_int.append(int(wb_sku))
            except (ValueError, TypeError):
                # Skip invalid wb_sku values
                st.warning(f"–ù–µ–≤–∞–ª–∏–¥–Ω—ã–π WB SKU –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ Punta: {wb_sku}")
                continue
        
        if not wb_skus_int:
            return {}
        
        # Build query to get punta data with dynamic columns
        # Use window function to get FIRST occurrence for each wb_sku
        if 'wb_sku' in available_columns:
            select_columns = ['wb_sku'] + data_columns
            
            punta_query = f"""
            WITH first_occurrences AS (
                SELECT {', '.join(f'"{col}"' for col in select_columns)},
                       ROW_NUMBER() OVER (PARTITION BY wb_sku ORDER BY ROWID) as rn
                FROM punta_table 
                WHERE wb_sku IN ({', '.join(['?'] * len(wb_skus_int))})
            )
            SELECT {', '.join(f'"{col}"' for col in select_columns)}
            FROM first_occurrences 
            WHERE rn = 1
            """
            
            punta_df = db_conn.execute(punta_query, wb_skus_int).fetchdf()
            
            if punta_df.empty:
                st.info(f"üì≠ –î–∞–Ω–Ω—ã–µ Punta –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è {len(wb_skus_int)} WB SKU")
                return {}
            
            st.success(f"‚úÖ –ù–∞–π–¥–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ Punta –¥–ª—è {len(punta_df)} –∏–∑ {len(wb_skus_int)} WB SKU (–ø–µ—Ä–≤—ã–µ –≤—Ö–æ–∂–¥–µ–Ω–∏—è)")
            
            # Convert to dict format with Excel-friendly formatting
            result_map = {}
            for _, row in punta_df.iterrows():
                wb_sku = str(row['wb_sku'])  # Convert back to string for consistency with input
                result_map[wb_sku] = {}
                
                for column in data_columns:
                    if column in row and pd.notna(row[column]):
                        raw_value = row[column]
                        
                        # Format values to be Excel-friendly
                        if column == 'sort':
                            # Convert sort to integer string to avoid decimals in Excel
                            try:
                                if pd.notna(raw_value) and raw_value != '' and str(raw_value).lower() != 'nan':
                                    formatted_value = str(int(float(raw_value)))
                                else:
                                    formatted_value = ""
                            except (ValueError, TypeError):
                                formatted_value = str(raw_value) if raw_value else ""
                        elif column == 'supply_n':
                            # Handle supply_n: keep only numeric values, exclude dates
                            try:
                                str_value = str(raw_value).strip()
                                # If it looks like a date (contains dots or slashes), make it empty
                                if '.' in str_value or '/' in str_value or len(str_value) > 4:
                                    formatted_value = ""
                                else:
                                    # Try to parse as integer to ensure it's numeric
                                    int(str_value)
                                    formatted_value = str_value
                            except (ValueError, TypeError):
                                formatted_value = ""
                        else:
                            # For other columns, convert to string as usual
                            formatted_value = str(raw_value).strip()
                            # Clean up common problematic values
                            if formatted_value.lower() in ['nan', 'none', 'null']:
                                formatted_value = ""
                        
                        result_map[wb_sku][column] = formatted_value
                    else:
                        result_map[wb_sku][column] = ""
            
            return result_map
        else:
            st.error("‚ùå –ö–æ–ª–æ–Ω–∫–∞ wb_sku –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Ç–∞–±–ª–∏—Ü–µ punta_table")
            return {}
        
    except Exception as e:
        st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö Punta: {e}")
        return {}

def get_dynamic_punta_columns(db_conn) -> List[str]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –∏–∑ punta_table –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è PUNTA_ –∫–æ–ª–æ–Ω–æ–∫.
    
    Returns:
        List of column names available in punta_table (excluding wb_sku)
    """
    try:
        from .db_crud import get_punta_table_columns
        
        all_columns = get_punta_table_columns(db_conn)
        
        # Remove wb_sku as it's the key column, not data column
        data_columns = [col for col in all_columns if col != 'wb_sku']
        
        return data_columns
        
    except Exception as e:
        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –∫–æ–ª–æ–Ω–∫–∏ Punta: {e}")
        return []

def update_punta_columns_dynamically(ws, column_map: Dict[str, int], wb_sku_data: Dict[str, Dict], 
                                   data_start_row: int = 9):
    """
    –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –≤—Å–µ PUNTA_ –∫–æ–ª–æ–Ω–∫–∏ –≤ Excel —Ñ–∞–π–ª–µ.
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ª—é–±—ã–µ –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å PUNTA_.
    
    Args:
        ws: Excel worksheet object
        column_map: Mapping of column names to column numbers
        wb_sku_data: Data for each WB SKU
        data_start_row: Row number where data starts (default 9)
    """
    # Find all PUNTA_ columns in the Excel file
    punta_columns = {col_name: col_num for col_name, col_num in column_map.items() 
                     if col_name.startswith('PUNTA_')}
    
    if not punta_columns:
        return  # –¢–∏—Ö–æ –≤—ã—Ö–æ–¥–∏–º –µ—Å–ª–∏ –Ω–µ—Ç PUNTA_ –∫–æ–ª–æ–Ω–æ–∫
    
    # Process each row
    for row_num in range(data_start_row, ws.max_row + 1):
        wb_sku_cell = ws.cell(row=row_num, column=column_map.get("WB_SKU", 2))
        wb_sku = str(wb_sku_cell.value).strip() if wb_sku_cell.value else ""
        
        if not wb_sku or wb_sku not in wb_sku_data:
            continue
        
        punta_data = wb_sku_data[wb_sku].get('punta', {})
        
        # Update each PUNTA_ column
        for col_name, col_num in punta_columns.items():
            # Extract the actual column name (remove PUNTA_ prefix)
            punta_col_name = col_name[6:]  # Remove 'PUNTA_' prefix
            punta_value = punta_data.get(punta_col_name, '')
            ws.cell(row=row_num, column=col_num).value = punta_value 