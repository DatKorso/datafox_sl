import duckdb
import streamlit as st
import os
import pandas as pd

# Import from other new utility modules
from .db_schema import get_table_schema_definition, get_table_columns_from_schema, get_defined_table_names
from .config_utils import get_db_path # For get_db_stats
from .data_cleaner import apply_data_cleaning, display_cleaning_report, validate_required_fields

# --- Data Import Functions ---

def import_data_from_dataframe(
    con: duckdb.DuckDBPyConnection,
    df: pd.DataFrame,
    table_name: str,
) -> tuple[bool, int, str]:
    """
    Imports data from a Pandas DataFrame into a specified DuckDB table according to hardcoded schema.
    Handles pre-update action (e.g., delete all existing data from the table).
    Renames DataFrame columns to match target DuckDB table column names based on schema.
    Applies specific data transformations as noted in the schema.
    Now includes data cleaning and validation with detailed logging.
    
    Special handling for punta_table: uses dynamic schema creation.
    (Formerly _import_data_from_dataframe in db_utils.py)
    """
    if not con:
        return False, 0, "No database connection."
    if df.empty:
        return True, 0, "Input DataFrame is empty. Nothing to import."
    
    # Special handling for punta_table - use dynamic import
    if table_name == "punta_table":
        return import_dynamic_punta_table(con, df)
    
    table_schema_def = get_table_schema_definition(table_name)
    if not table_schema_def:
        return False, 0, f"No schema definition found for table '{table_name}' via db_schema.py."

    # Check if table uses dynamic schema
    columns_info = table_schema_def.get("columns")
    if columns_info == "DYNAMIC":
        return False, 0, f"Table '{table_name}' uses dynamic schema but special handling is not implemented. Please add specific logic."

    schema_columns_info = get_table_columns_from_schema(table_name)
    if not schema_columns_info:
        return False, 0, f"No column schema information found for table '{table_name}' via db_schema.py."

    # 0. Validate required fields
    validation_issues = validate_required_fields(df, schema_columns_info)
    if validation_issues:
        st.error("âŒ ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…:")
        for issue in validation_issues:
            st.write(f"â€¢ {issue['message']}")
        return False, 0, "Data validation failed. See details above."

    # 0.5. Apply data cleaning BEFORE other transformations
    st.info("ðŸ§¹ ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° Ð¸ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…...")
    cleaned_df, cleaning_issues = apply_data_cleaning(df, table_name, schema_columns_info)
    
    # Display cleaning report
    display_cleaning_report(cleaning_issues, table_name)

    # 1. Pre-Update Action
    pre_update_sql = table_schema_def.get("pre_update_action")
    if pre_update_sql:
        try:
            con.execute(pre_update_sql)
        except Exception as e:
            return False, 0, f"Error executing pre-update action for table '{table_name}': {e}. SQL: {pre_update_sql}"

    # 2. Prepare DataFrame: Select and rename columns, apply transformations
    df_to_import = pd.DataFrame()
    expected_target_columns = []
    try:
        for target_col, sql_type, source_col, notes in schema_columns_info:
            expected_target_columns.append(target_col)
            if source_col in cleaned_df.columns:
                df_to_import[target_col] = cleaned_df[source_col].copy()

                if notes == "remove_single_quotes":
                    df_to_import[target_col] = df_to_import[target_col].astype(str).str.replace("'", "", regex=False)
                elif notes == "convert to date":
                    try:
                        df_to_import[target_col] = pd.to_datetime(df_to_import[target_col], errors='coerce').dt.date
                    except Exception as e_date:
                        st.warning(f"Could not convert column {target_col} to date for table {table_name}. Error: {e_date}. Leaving as is.")
                elif notes == "round_to_integer":
                    try:
                        # The data should already be cleaned by data_cleaner, but apply final rounding
                        numeric_col = pd.to_numeric(df_to_import[target_col], errors='coerce')
                        df_to_import[target_col] = numeric_col.apply(lambda x: int(round(x)) if pd.notnull(x) else pd.NA)
                        df_to_import[target_col] = df_to_import[target_col].astype('Int64') # Convert to nullable integer type
                    except Exception as e_price:
                        st.warning(f"Could not convert column {target_col} to rounded integer for table {table_name}. Error: {e_price}. Leaving as is.")
                elif notes == "convert_to_integer":
                    try:
                        # Convert string/varchar wb_sku to integer
                        numeric_col = pd.to_numeric(df_to_import[target_col], errors='coerce')
                        df_to_import[target_col] = numeric_col.astype('Int64') # Convert to nullable integer type
                        
                        # Count and log conversion issues
                        null_count = df_to_import[target_col].isna().sum()
                        if null_count > 0:
                            st.warning(f"Ð’Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ: {null_count} Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹ Ð² ÐºÐ¾Ð»Ð¾Ð½ÐºÐµ {target_col} Ð½Ðµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð² Ñ‡Ð¸ÑÐ»Ð° Ð¸ Ð±Ñ‹Ð»Ð¸ Ð·Ð°Ð¼ÐµÐ½ÐµÐ½Ñ‹ Ð½Ð° NULL")
                    except Exception as e_conv:
                        st.warning(f"Could not convert column {target_col} to integer for table {table_name}. Error: {e_conv}. Leaving as is.")
            else:
                return False, 0, f"Source column '{source_col}' defined in schema not found in input data for table '{table_name}'."
    
        for target_col, _, _, _ in schema_columns_info:
            if target_col not in df_to_import.columns:
                df_to_import[target_col] = pd.NA
        
        df_to_import = df_to_import[expected_target_columns]

    except Exception as e_prep:
        return False, 0, f"Error preparing DataFrame for table '{table_name}': {e_prep}"

    # 3. Final check: show preview of data to be imported
    st.info("ðŸ“Š ÐŸÑ€ÐµÐ´Ð¿Ñ€Ð¾ÑÐ¼Ð¾Ñ‚Ñ€ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð°:")
    st.dataframe(df_to_import.head(10))
    
    # Show summary statistics
    total_rows = len(df_to_import)
    null_summary = {}
    for col in df_to_import.columns:
        null_count = df_to_import[col].isna().sum()
        if null_count > 0:
            null_summary[col] = null_count
    
    if null_summary:
        st.info("ðŸ“‹ Ð¡Ð²Ð¾Ð´ÐºÐ° Ð¿Ð¾ Ð¿ÑƒÑÑ‚Ñ‹Ð¼ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸ÑÐ¼:")
        for col, count in null_summary.items():
            st.write(f"â€¢ **{col}**: {count} Ð¿ÑƒÑÑ‚Ñ‹Ñ… Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹ Ð¸Ð· {total_rows} ({count/total_rows*100:.1f}%)")

    # 4. Import data into DuckDB table
    try:
        con.register('temp_df_to_import', df_to_import)
        con.execute(f'INSERT INTO "{table_name}" SELECT * FROM temp_df_to_import;')
        con.unregister('temp_df_to_import')
        
        records_imported = len(df_to_import)
        return True, records_imported, ""
    except Exception as e_import:
        return False, 0, f"Error importing data into table '{table_name}': {e_import}"

def import_dynamic_punta_table(
    con: duckdb.DuckDBPyConnection,
    df: pd.DataFrame
) -> tuple[bool, int, str]:
    """
    Ð”Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð² Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ punta_table Ñ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¼ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸ÐµÐ¼ ÑÑ…ÐµÐ¼Ñ‹.
    Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ DuckDB Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ð²Ñ‹Ð²Ð¾Ð´Ð° Ñ‚Ð¸Ð¿Ð¾Ð² Ð´Ð°Ð½Ð½Ñ‹Ñ….
    Ð¡Ð¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð´Ð»Ñ wb_sku - ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð°Ñ†Ð¸Ñ Ð² INTEGER, ÐµÑÐ»Ð¸ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾.
    """
    if not con:
        return False, 0, "No database connection."
    if df.empty:
        return True, 0, "Input DataFrame is empty. Nothing to import."
    
    try:
        # 1. ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… - ÑƒÐ´Ð°Ð»ÑÐµÐ¼ Ð¿Ð¾Ð»Ð½Ð¾ÑÑ‚ÑŒÑŽ Ð¿ÑƒÑÑ‚Ñ‹Ðµ ÑÑ‚Ñ€Ð¾ÐºÐ¸
        df_clean = df.dropna(how='all').copy()
        
        if df_clean.empty:
            return True, 0, "All rows were empty after cleaning."
        
        st.info(f"ðŸ“Š ÐžÑ‡Ð¸Ñ‰ÐµÐ½Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ…: {len(df)} â†’ {len(df_clean)} ÑÑ‚Ñ€Ð¾Ðº")
        
        # 2. Ð¡Ð¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° wb_sku - Ð¿Ð¾Ð¿Ñ‹Ñ‚Ð°Ñ‚ÑŒÑÑ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð² INTEGER
        if 'wb_sku' in df_clean.columns:
            st.info("ðŸ”„ Ð¡Ð¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° wb_sku...")
            original_count = len(df_clean)
            
            # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ wb_sku Ð² Ñ‡Ð¸ÑÐ»Ð°, Ð³Ð´Ðµ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾
            df_clean['wb_sku'] = pd.to_numeric(df_clean['wb_sku'], errors='coerce')
            
            # Ð£Ð´Ð°Ð»ÑÐµÐ¼ ÑÑ‚Ñ€Ð¾ÐºÐ¸ Ñ Ð½ÐµÐ²Ð°Ð»Ð¸Ð´Ð½Ñ‹Ð¼Ð¸ wb_sku (ÐµÑÐ»Ð¸ wb_sku ÑÐ²Ð»ÑÐµÑ‚ÑÑ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ð¼ Ð¿Ð¾Ð»ÐµÐ¼)
            df_clean = df_clean.dropna(subset=['wb_sku'])
            df_clean['wb_sku'] = df_clean['wb_sku'].astype('Int64')
            
            invalid_count = original_count - len(df_clean)
            if invalid_count > 0:
                st.warning(f"âš ï¸ Ð˜ÑÐºÐ»ÑŽÑ‡ÐµÐ½Ð¾ {invalid_count} ÑÑ‚Ñ€Ð¾Ðº Ñ Ð½ÐµÐ²Ð°Ð»Ð¸Ð´Ð½Ñ‹Ð¼Ð¸ wb_sku")
            
            st.success(f"âœ… wb_sku ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½ Ð² INTEGER Ð´Ð»Ñ {len(df_clean)} ÑÑ‚Ñ€Ð¾Ðº")
        
        # 3. Ð£Ð´Ð°Ð»ÑÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰ÑƒÑŽ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ
        con.execute("DROP TABLE IF EXISTS punta_table;")
        st.info("ðŸ—‘ï¸ Ð¡ÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð°Ñ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð° punta_table ÑƒÐ´Ð°Ð»ÐµÐ½Ð°")
        
        # 4. Ð ÐµÐ³Ð¸ÑÑ‚Ñ€Ð¸Ñ€ÑƒÐµÐ¼ DataFrame Ð²Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½ÑƒÑŽ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ
        con.register('temp_punta_df', df_clean)
        
        # 5. Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð½Ð¾Ð²ÑƒÑŽ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ Ñ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¼ Ð²Ñ‹Ð²Ð¾Ð´Ð¾Ð¼ ÑÑ…ÐµÐ¼Ñ‹
        con.execute("""
            CREATE TABLE punta_table AS 
            SELECT * FROM temp_punta_df;
        """)
        
        # 6. ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½ÑƒÑŽ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ
        con.unregister('temp_punta_df')
        
        # 7. ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ ÑÐ¾Ð·Ð´Ð°Ð½Ð½Ð¾Ð¹ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ðµ
        schema_info = con.execute("DESCRIBE punta_table;").fetchdf()
        st.success("âœ… Ð¢Ð°Ð±Ð»Ð¸Ñ†Ð° punta_table ÑÐ¾Ð·Ð´Ð°Ð½Ð° Ñ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¼ Ð²Ñ‹Ð²Ð¾Ð´Ð¾Ð¼ ÑÑ…ÐµÐ¼Ñ‹:")
        st.dataframe(schema_info, use_container_width=True)
        
        # 8. ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð¿Ñ€ÐµÐ²ÑŒÑŽ Ð´Ð°Ð½Ð½Ñ‹Ñ…
        preview_data = con.execute("SELECT * FROM punta_table LIMIT 5;").fetchdf()
        st.info("ðŸ“‹ ÐŸÑ€ÐµÐ²ÑŒÑŽ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð² Ð½Ð¾Ð²Ð¾Ð¹ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ðµ:")
        st.dataframe(preview_data, use_container_width=True)
        
        records_imported = len(df_clean)
        return True, records_imported, ""
        
    except Exception as e:
        return False, 0, f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð´Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¾Ð¼ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ðµ punta_table: {str(e)}"

def get_punta_table_columns(con: duckdb.DuckDBPyConnection) -> list[str]:
    """
    ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº Ð²ÑÐµÑ… ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº Ð² Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ðµ punta_table (Ð´Ð»Ñ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ°Ð»ÑŒÐ½Ð¾Ð¹ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹).
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¿ÑƒÑÑ‚Ð¾Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº ÐµÑÐ»Ð¸ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð° Ð½Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚.
    """
    if not con:
        return []
    
    try:
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹
        table_exists = con.execute("""
            SELECT COUNT(*) 
            FROM information_schema.tables 
            WHERE table_name = 'punta_table' AND table_schema = 'main'
        """).fetchone()[0]
        
        if table_exists == 0:
            return []
        
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ ÑÐ¿Ð¸ÑÐ¾Ðº ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº
        columns_df = con.execute("DESCRIBE punta_table;").fetchdf()
        return columns_df['column_name'].tolist()
        
    except Exception as e:
        st.warning(f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ punta_table: {e}")
        return []

# --- Database Statistics ---

def get_db_stats(con: duckdb.DuckDBPyConnection) -> dict:
    """
    Retrieves statistics from the database, such as table count, total records per table,
    and overall total records for managed tables, as well as DB file size.
    """
    if not con:
        return {
            'table_count': None,
            'total_records': None,
            'db_file_size_mb': None,
            'table_record_counts': {},
            'error': 'No database connection.'
        }

    stats = {
        'table_count': 0,
        'total_records': 0,
        'db_file_size_mb': None,
        'table_record_counts': {}
    }

    try:
        table_count_result = con.execute("SELECT COUNT(table_name) FROM information_schema.tables WHERE table_schema = 'main';").fetchone()
        stats['table_count'] = table_count_result[0] if table_count_result else 0

        relevant_table_names = get_defined_table_names() # From db_schema.py
        
        total_records_count = 0
        if relevant_table_names:
            for table_name in relevant_table_names:
                try:
                    check_exists = con.execute(f"SELECT 1 FROM information_schema.tables WHERE table_name = '{table_name}' AND table_schema = 'main';").fetchone()
                    if check_exists:
                        count_result = con.execute(f'SELECT COUNT(*) FROM "{table_name}";').fetchone()
                        current_table_records = count_result[0] if count_result else 0
                        stats['table_record_counts'][table_name] = current_table_records
                        total_records_count += current_table_records
                    else:
                        stats['table_record_counts'][table_name] = 0
                except Exception as e_count:
                    print(f"Could not get record count for table {table_name}: {e_count}")
                    stats['table_record_counts'][table_name] = f"Error: {e_count}"
            stats['total_records'] = total_records_count
        else:
            stats['total_records'] = None

        db_path = get_db_path() # From config_utils.py
        if db_path and os.path.exists(db_path):
            try:
                file_size_bytes = os.path.getsize(db_path)
                stats['db_file_size_mb'] = round(file_size_bytes / (1024 * 1024), 2)
            except Exception as e_size:
                print(f"Could not get database file size: {e_size}")
                stats['db_file_size_mb'] = f"Error: {e_size}"
        
        return stats

    except Exception as e:
        print(f"Error getting database stats: {e}")
        stats['error'] = str(e)
        if 'table_count' not in stats or stats['table_count'] is None: stats['table_count'] = 0
        if 'total_records' not in stats or stats['total_records'] is None: stats['total_records'] = 0 
        return stats

def get_all_db_tables(con: duckdb.DuckDBPyConnection) -> list[str]:
    """
    Returns a list of ALL table names that exist in the 'main' schema of the database.
    Used for the 'View Data' page to allow viewing any table.
    """
    if not con:
        return []
    
    try:
        tables_result = con.execute("SELECT table_name FROM information_schema.tables WHERE table_schema = 'main' ORDER BY table_name;").fetchall()
        return [row[0] for row in tables_result] if tables_result else []
    except Exception as e:
        msg = f"Error fetching list of all database tables: {e}"
        print(msg)
        if callable(st.error): st.error(msg)
        return [] 