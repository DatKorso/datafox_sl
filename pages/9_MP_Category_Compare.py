"""
Streamlit page for comparing product categories between marketplaces.

This page allows users to:
- Input Wildberries or Ozon SKUs to find linked products
- Manage category mapping table between WB and Ozon
- View category discrepancies between linked products
- Edit category mappings directly in the interface
"""
import streamlit as st
import pandas as pd
from utils.db_connection import connect_db
from utils.db_search_helpers import get_normalized_wb_barcodes, get_ozon_barcodes_and_identifiers
from utils.category_helpers import (
    get_unique_wb_categories, get_unique_oz_categories, suggest_category_mappings,
    get_unmapped_categories, get_category_usage_stats, validate_category_mapping,
    export_category_mappings_to_csv, import_category_mappings_from_csv
)
from datetime import datetime

st.set_page_config(page_title="Category Compare - Marketplace Analyzer", layout="wide")
st.title("üîÑ –°–≤–µ—Ä–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –º–µ–∂–¥—É –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–∞–º–∏")
st.markdown("---")

# --- Database Connection ---
def get_db_connection():
    """Get database connection for category comparison operations."""
    conn = connect_db()
    if not conn:
        st.error("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –≤ Settings.")
        if st.button("–ü–µ—Ä–µ–π—Ç–∏ –≤ Settings", key="db_settings_button_cat"):
            st.switch_page("pages/3_Settings.py")
        st.stop()
    return conn

# Initialize connection - will be used throughout the page
conn = get_db_connection()

# --- Helper Functions ---

def create_category_mapping_table_if_not_exists(db_conn):
    """Creates category_mapping table if it doesn't exist."""
    try:
        # Verify connection
        if not db_conn:
            st.error("–°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ")
            return False
            
        # Check if table exists
        result = db_conn.execute("SELECT table_name FROM information_schema.tables WHERE table_name = 'category_mapping';").fetchone()
        
        if not result:
            # Create sequence first
            db_conn.execute("CREATE SEQUENCE IF NOT EXISTS category_mapping_seq START 1")
            
            # Create table
            create_sql = """
            CREATE TABLE category_mapping (
                id INTEGER PRIMARY KEY DEFAULT nextval('category_mapping_seq'),
                wb_category VARCHAR,
                oz_category VARCHAR,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                notes TEXT
            );
            """
            db_conn.execute(create_sql)
            st.success("–¢–∞–±–ª–∏—Ü–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å–æ–∑–¥–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        return True
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ç–∞–±–ª–∏—Ü—ã: {e}")
        return False

def get_category_mappings(db_conn):
    """Gets all category mappings from database."""
    try:
        query = """
        SELECT id, wb_category, oz_category, created_at, notes 
        FROM category_mapping 
        ORDER BY wb_category, oz_category
        """
        return db_conn.execute(query).fetchdf()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {e}")
        return pd.DataFrame()

def add_category_mapping(db_conn, wb_category, oz_category, notes=""):
    """Adds new category mapping."""
    try:
        # Check if mapping already exists
        check_query = "SELECT id FROM category_mapping WHERE wb_category = ? AND oz_category = ?"
        existing = db_conn.execute(check_query, [wb_category, oz_category]).fetchone()
        
        if existing:
            st.warning(f"–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ '{wb_category}' ‚Üî '{oz_category}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            return False
        
        insert_query = """
        INSERT INTO category_mapping (wb_category, oz_category, notes) 
        VALUES (?, ?, ?)
        """
        db_conn.execute(insert_query, [wb_category, oz_category, notes])
        st.success(f"–î–æ–±–∞–≤–ª–µ–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: '{wb_category}' ‚Üî '{oz_category}'")
        return True
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è: {e}")
        return False

def delete_category_mapping(db_conn, mapping_id):
    """Deletes category mapping by ID."""
    try:
        delete_query = "DELETE FROM category_mapping WHERE id = ?"
        db_conn.execute(delete_query, [mapping_id])
        st.success("–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —É–¥–∞–ª–µ–Ω–æ")
        return True
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è: {e}")
        return False

def find_linked_products_with_categories(db_conn, input_skus, search_by="wb_sku"):
    """
    Finds linked products between marketplaces and gets their categories.
    
    Args:
        db_conn: Database connection
        input_skus: List of SKUs to search for
        search_by: "wb_sku" or "oz_sku"
        
    Returns:
        DataFrame with linked products and their categories
    """
    if not input_skus:
        return pd.DataFrame()
    
    try:
        # Verify connection is still active
        if not db_conn:
            st.error("–°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ")
            return pd.DataFrame()
        
        # Test connection with a simple query
        try:
            db_conn.execute("SELECT 1").fetchone()
        except Exception as e:
            st.error(f"–°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö –ø–æ—Ç–µ—Ä—è–Ω–æ: {e}")
            return pd.DataFrame()
        
        if search_by == "wb_sku":
            # Find linked Ozon products via barcodes
            try:
                wb_barcodes_df = get_normalized_wb_barcodes(db_conn, wb_skus=input_skus)
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —à—Ç—Ä–∏—Ö–∫–æ–¥–æ–≤ WB: {e}")
                return pd.DataFrame()
                
            if wb_barcodes_df.empty:
                st.info("–ù–µ –Ω–∞–π–¥–µ–Ω—ã —à—Ç—Ä–∏—Ö–∫–æ–¥—ã –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –∞—Ä—Ç–∏–∫—É–ª–æ–≤ WB")
                return pd.DataFrame()
            
            try:
                oz_barcodes_ids_df = get_ozon_barcodes_and_identifiers(db_conn)
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —à—Ç—Ä–∏—Ö–∫–æ–¥–æ–≤ Ozon: {e}")
                return pd.DataFrame()
                
            if oz_barcodes_ids_df.empty:
                st.info("–í –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —à—Ç—Ä–∏—Ö–∫–æ–¥—ã Ozon")
                return pd.DataFrame()
            
            # Prepare data for merge
            wb_barcodes_df = wb_barcodes_df.rename(columns={'individual_barcode_wb': 'barcode'})
            oz_barcodes_ids_df = oz_barcodes_ids_df.rename(columns={'oz_barcode': 'barcode'})
            
            # Ensure barcode consistency
            wb_barcodes_df['barcode'] = wb_barcodes_df['barcode'].astype(str).str.strip()
            oz_barcodes_ids_df['barcode'] = oz_barcodes_ids_df['barcode'].astype(str).str.strip()
            wb_barcodes_df['wb_sku'] = wb_barcodes_df['wb_sku'].astype(str)
            oz_barcodes_ids_df['oz_sku'] = oz_barcodes_ids_df['oz_sku'].astype(str)
            
            # Remove empty barcodes and duplicates
            wb_barcodes_df = wb_barcodes_df[wb_barcodes_df['barcode'] != ''].drop_duplicates()
            oz_barcodes_ids_df = oz_barcodes_ids_df[oz_barcodes_ids_df['barcode'] != ''].drop_duplicates()
            
            # Join on common barcodes
            linked_df = pd.merge(wb_barcodes_df, oz_barcodes_ids_df, on='barcode', how='inner')
            
            if linked_df.empty:
                return pd.DataFrame()
            
            # Get WB categories
            wb_skus_list = linked_df['wb_sku'].unique().tolist()
            wb_categories_query = f"""
            SELECT wb_sku, wb_category 
            FROM wb_products 
            WHERE wb_sku IN ({', '.join(['?'] * len(wb_skus_list))})
            """
            wb_categories_df = db_conn.execute(wb_categories_query, wb_skus_list).fetchdf()
            wb_categories_df['wb_sku'] = wb_categories_df['wb_sku'].astype(str)
            
            # Get Ozon categories (from oz_category_products table via oz_vendor_code)
            # and link oz_vendor_code to oz_sku using oz_products table
            oz_vendor_codes_list = linked_df['oz_vendor_code'].unique().tolist()
            oz_categories_query = f"""
            SELECT 
                cp.oz_vendor_code, 
                cp.type as oz_category,
                p.oz_sku
            FROM oz_category_products cp
            LEFT JOIN oz_products p ON cp.oz_vendor_code = p.oz_vendor_code
            WHERE cp.oz_vendor_code IN ({', '.join(['?'] * len(oz_vendor_codes_list))})
            """
            oz_categories_df = db_conn.execute(oz_categories_query, oz_vendor_codes_list).fetchdf()
            if 'oz_sku' in oz_categories_df.columns:
                oz_categories_df['oz_sku'] = oz_categories_df['oz_sku'].astype(str)
            
            # Merge all data
            result_df = linked_df[['wb_sku', 'oz_sku', 'oz_vendor_code', 'barcode']].drop_duplicates()
            result_df = pd.merge(result_df, wb_categories_df, on='wb_sku', how='left')
            result_df = pd.merge(result_df, oz_categories_df, on='oz_vendor_code', how='left')
            
            # Update oz_sku from the category join if it's more accurate
            result_df['oz_sku'] = result_df['oz_sku_y'].fillna(result_df['oz_sku_x'])
            result_df = result_df.drop(columns=['oz_sku_x', 'oz_sku_y'], errors='ignore')
            
        else:  # search_by == "oz_sku"
            # Similar logic but starting from Ozon SKUs
            oz_skus_for_query = list(set(input_skus))
            
            # Get Ozon products with categories and barcodes
            # Use oz_products as the main table and join categories via oz_vendor_code
            oz_query = f"""
            SELECT DISTINCT
                p.oz_sku,
                p.oz_vendor_code,
                cp.type as oz_category,
                b.oz_barcode as barcode
            FROM oz_products p
            LEFT JOIN oz_category_products cp ON p.oz_vendor_code = cp.oz_vendor_code
            LEFT JOIN oz_barcodes b ON p.oz_product_id = b.oz_product_id
            WHERE p.oz_sku IN ({', '.join(['?'] * len(oz_skus_for_query))})
                AND NULLIF(TRIM(b.oz_barcode), '') IS NOT NULL
            """
            
            oz_data_df = db_conn.execute(oz_query, oz_skus_for_query).fetchdf()
            
            if oz_data_df.empty:
                return pd.DataFrame()
            
            # Get WB products with same barcodes
            wb_query = f"""
            SELECT 
                p.wb_sku,
                p.wb_category,
                TRIM(b.barcode) AS barcode
            FROM wb_products p,
            UNNEST(regexp_split_to_array(COALESCE(p.wb_barcodes, ''), E'[\\s;]+')) AS b(barcode)
            WHERE NULLIF(TRIM(b.barcode), '') IS NOT NULL
            """
            
            wb_data_df = db_conn.execute(wb_query).fetchdf()
            
            if wb_data_df.empty:
                return pd.DataFrame()
            
            # Ensure data types
            oz_data_df['barcode'] = oz_data_df['barcode'].astype(str).str.strip()
            wb_data_df['barcode'] = wb_data_df['barcode'].astype(str).str.strip()
            oz_data_df['oz_sku'] = oz_data_df['oz_sku'].astype(str)
            wb_data_df['wb_sku'] = wb_data_df['wb_sku'].astype(str)
            
            # Remove empty barcodes
            oz_data_df = oz_data_df[oz_data_df['barcode'] != ''].drop_duplicates()
            wb_data_df = wb_data_df[wb_data_df['barcode'] != ''].drop_duplicates()
            
            # Join on common barcodes
            result_df = pd.merge(oz_data_df, wb_data_df, on='barcode', how='inner')
        
        return result_df
        
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤: {e}")
        return pd.DataFrame()

def analyze_category_discrepancies(db_conn, linked_products_df, show_all=False):
    """
    Analyzes category discrepancies based on category mapping table.
    
    Args:
        db_conn: Database connection
        linked_products_df: DataFrame with linked products
        show_all: If True, shows all matches including correct ones
    
    Returns:
        DataFrame with discrepancies (or all matches if show_all=True)
    """
    if linked_products_df.empty:
        return pd.DataFrame()
    
    try:
        # Get category mappings
        mappings_df = get_category_mappings(db_conn)
        
        if mappings_df.empty:
            st.warning("–¢–∞–±–ª–∏—Ü–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø—É—Å—Ç–∞. –î–æ–±–∞–≤—å—Ç–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
            return pd.DataFrame()
        
        # Create mapping dictionary
        category_map = dict(zip(mappings_df['wb_category'], mappings_df['oz_category']))
        
        # Analyze all products
        results = []
        
        for _, row in linked_products_df.iterrows():
            wb_category = row.get('wb_category', '')
            oz_category = row.get('oz_category', '')
            
            if pd.isna(wb_category) or pd.isna(oz_category):
                if show_all:
                    results.append({
                        'wb_sku': row['wb_sku'],
                        'oz_sku': row['oz_sku'],
                        'oz_vendor_code': row.get('oz_vendor_code', ''),
                        'barcode': row['barcode'],
                        'wb_category': str(wb_category) if not pd.isna(wb_category) else '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö',
                        'oz_category_actual': str(oz_category) if not pd.isna(oz_category) else '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö',
                        'oz_category_expected': '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö',
                        'discrepancy_type': '–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –¥–∞–Ω–Ω—ã–µ –æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö',
                        'status': '‚ùå –û—à–∏–±–∫–∞'
                    })
                continue
                
            wb_category = str(wb_category).strip()
            oz_category = str(oz_category).strip()
            
            # Check if WB category has a mapping
            expected_oz_category = category_map.get(wb_category)
            
            if expected_oz_category:
                if expected_oz_category == oz_category:
                    # Categories match correctly
                    if show_all:
                        results.append({
                            'wb_sku': row['wb_sku'],
                            'oz_sku': row['oz_sku'],
                            'oz_vendor_code': row.get('oz_vendor_code', ''),
                            'barcode': row['barcode'],
                            'wb_category': wb_category,
                            'oz_category_actual': oz_category,
                            'oz_category_expected': expected_oz_category,
                            'discrepancy_type': '–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç',
                            'status': '‚úÖ –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ'
                        })
                else:
                    # Categories don't match
                    results.append({
                        'wb_sku': row['wb_sku'],
                        'oz_sku': row['oz_sku'],
                        'oz_vendor_code': row.get('oz_vendor_code', ''),
                        'barcode': row['barcode'],
                        'wb_category': wb_category,
                        'oz_category_actual': oz_category,
                        'oz_category_expected': expected_oz_category,
                        'discrepancy_type': '–ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π',
                        'status': '‚ö†Ô∏è –†–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ'
                    })
            else:
                # No mapping configured for this WB category
                results.append({
                    'wb_sku': row['wb_sku'],
                    'oz_sku': row['oz_sku'],
                    'oz_vendor_code': row.get('oz_vendor_code', ''),
                    'barcode': row['barcode'],
                    'wb_category': wb_category,
                    'oz_category_actual': oz_category,
                    'oz_category_expected': '–ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ',
                    'discrepancy_type': '–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ',
                    'status': '‚ùì –ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ'
                })
        
        return pd.DataFrame(results)
        
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {e}")
        return pd.DataFrame()

# Initialize database table
create_category_mapping_table_if_not_exists(conn)

# --- Main UI ---

# Tabs for different functionality
tab1, tab2, tab3 = st.tabs(["üîç –ê–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–π", "‚öôÔ∏è –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è–º–∏", "üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"])

with tab1:
    st.header("–ê–Ω–∞–ª–∏–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
    
    # Input section
    col1, col2 = st.columns([2, 1])
    
    with col1:
        search_method = st.radio(
            "–ü–æ–∏—Å–∫ –ø–æ:",
            ["–ê—Ä—Ç–∏–∫—É–ª–∞–º WB (wb_sku)", "–ê—Ä—Ç–∏–∫—É–ª–∞–º Ozon (oz_sku)"],
            index=0
        )
        
        search_by = "wb_sku" if "WB" in search_method else "oz_sku"
        
        input_skus_text = st.text_area(
            f"–í–≤–µ–¥–∏—Ç–µ {search_method.lower()} (–æ–¥–∏–Ω –Ω–∞ —Å—Ç—Ä–æ–∫—É –∏–ª–∏ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª):",
            height=100,
            help="–ù–∞–ø—Ä–∏–º–µ—Ä:\n123456\n789012\n–∏–ª–∏\n123456 789012"
        )
    
    with col2:
        st.info("""
        **–ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç:**
        1. –í–≤–µ–¥–∏—Ç–µ –∞—Ä—Ç–∏–∫—É–ª—ã
        2. –°–∏—Å—Ç–µ–º–∞ –Ω–∞–π–¥–µ—Ç —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã —á–µ—Ä–µ–∑ —à—Ç—Ä–∏—Ö–∫–æ–¥—ã
        3. –°—Ä–∞–≤–Ω–∏—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å —Ç–∞–±–ª–∏—Ü–µ–π —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π
        4. –ü–æ–∫–∞–∂–µ—Ç —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è
        """)
    
    # Options for analysis
    show_all_matches = st.checkbox(
        "üîç –ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã (–≤–∫–ª—é—á–∞—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è)",
        value=False,
        help="–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ç–æ–≤–∞—Ä—ã —Å —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è–º–∏. "
             "–í–∫–ª—é—á–∏—Ç–µ —ç—Ç—É –æ–ø—Ü–∏—é, —á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã –∏ –∏—Ö —Å—Ç–∞—Ç—É—Å."
    )
    
    button_text = "üöÄ –ù–∞–π—Ç–∏ –≤—Å–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π" if show_all_matches else "üöÄ –ù–∞–π—Ç–∏ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö"
    
    if st.button(button_text, type="primary"):
        if not input_skus_text.strip():
            st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –∞—Ä—Ç–∏–∫—É–ª—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        else:
            # Parse input SKUs
            input_skus = []
            for line in input_skus_text.strip().split('\n'):
                for sku in line.split():
                    sku = sku.strip()
                    if sku:
                        input_skus.append(sku)
            
            if not input_skus:
                st.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö –∞—Ä—Ç–∏–∫—É–ª–æ–≤")
            else:
                with st.spinner("–ü–æ–∏—Å–∫ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –∏ –∞–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–π..."):
                    # Create fresh connection for this operation
                    analysis_conn = get_db_connection()
                    
                    try:
                        # Find linked products
                        linked_df = find_linked_products_with_categories(analysis_conn, input_skus, search_by)
                        
                        if linked_df.empty:
                            st.info("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
                        else:
                            st.success(f"–ù–∞–π–¥–µ–Ω–æ {len(linked_df)} —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤")
                            
                            # Analyze category matches/discrepancies
                            results_df = analyze_category_discrepancies(analysis_conn, linked_df, show_all=show_all_matches)
                            
                            if results_df.empty:
                                if show_all_matches:
                                    st.info("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
                                else:
                                    st.success("üéâ –†–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!")
                            else:
                                # Filter for statistics
                                if show_all_matches:
                                    correct_matches = results_df[results_df['status'] == '‚úÖ –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ']
                                    discrepancies = results_df[results_df['status'].isin(['‚ö†Ô∏è –†–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ', '‚ùì –ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ', '‚ùå –û—à–∏–±–∫–∞'])]
                                    
                                    # Show summary
                                    col1, col2, col3 = st.columns(3)
                                    with col1:
                                        st.metric("–í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤", len(results_df))
                                    with col2:
                                        st.metric("–ö–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π", len(correct_matches), 
                                                 delta=f"{len(correct_matches)/len(results_df)*100:.1f}%")
                                    with col3:
                                        st.metric("–ü—Ä–æ–±–ª–µ–º–Ω—ã—Ö", len(discrepancies), 
                                                 delta=f"{len(discrepancies)/len(results_df)*100:.1f}%")
                                    
                                    st.subheader("–í—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
                                else:
                                    st.warning(f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ {len(results_df)} —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö")
                                    st.subheader("–†–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö")
                                
                                # Display results
                                display_columns = [
                                    'status', 'wb_sku', 'oz_sku', 'oz_vendor_code', 
                                    'wb_category', 'oz_category_actual', 'oz_category_expected',
                                    'discrepancy_type'
                                ]
                                
                                # Color-code the status column for better visibility
                                st.dataframe(
                                    results_df[display_columns],
                                    use_container_width=True,
                                    hide_index=True,
                                    column_config={
                                        'status': st.column_config.TextColumn('–°—Ç–∞—Ç—É—Å', width="small"),
                                        'wb_sku': 'WB SKU',
                                        'oz_sku': 'Ozon SKU', 
                                        'oz_vendor_code': '–ö–æ–¥ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞',
                                        'wb_category': '–ö–∞—Ç–µ–≥–æ—Ä–∏—è WB',
                                        'oz_category_actual': '–ö–∞—Ç–µ–≥–æ—Ä–∏—è Ozon (—Ñ–∞–∫—Ç)',
                                        'oz_category_expected': '–ö–∞—Ç–µ–≥–æ—Ä–∏—è Ozon (–æ–∂–∏–¥–∞–µ—Ç—Å—è)',
                                        'discrepancy_type': '–û–ø–∏—Å–∞–Ω–∏–µ'
                                    }
                                )
                                
                                # Filter options for all matches view
                                if show_all_matches and len(results_df) > 10:
                                    st.subheader("–§–∏–ª—å—Ç—Ä—ã")
                                    
                                    filter_col1, filter_col2 = st.columns(2)
                                    
                                    with filter_col1:
                                        status_filter = st.multiselect(
                                            "–§–∏–ª—å—Ç—Ä –ø–æ —Å—Ç–∞—Ç—É—Å—É:",
                                            options=results_df['status'].unique(),
                                            default=results_df['status'].unique(),
                                            key="status_filter"
                                        )
                                    
                                    with filter_col2:
                                        wb_category_filter = st.selectbox(
                                            "–§–∏–ª—å—Ç—Ä –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ WB:",
                                            options=["–í—Å–µ"] + list(results_df['wb_category'].unique()),
                                            index=0,
                                            key="wb_category_filter"
                                        )
                                    
                                    # Apply filters
                                    filtered_df = results_df[results_df['status'].isin(status_filter)]
                                    if wb_category_filter != "–í—Å–µ":
                                        filtered_df = filtered_df[filtered_df['wb_category'] == wb_category_filter]
                                    
                                    if len(filtered_df) != len(results_df):
                                        st.subheader("–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
                                        st.dataframe(
                                            filtered_df[display_columns],
                                            use_container_width=True,
                                            hide_index=True,
                                            column_config={
                                                'status': st.column_config.TextColumn('–°—Ç–∞—Ç—É—Å', width="small"),
                                                'wb_sku': 'WB SKU',
                                                'oz_sku': 'Ozon SKU', 
                                                'oz_vendor_code': '–ö–æ–¥ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞',
                                                'wb_category': '–ö–∞—Ç–µ–≥–æ—Ä–∏—è WB',
                                                'oz_category_actual': '–ö–∞—Ç–µ–≥–æ—Ä–∏—è Ozon (—Ñ–∞–∫—Ç)',
                                                'oz_category_expected': '–ö–∞—Ç–µ–≥–æ—Ä–∏—è Ozon (–æ–∂–∏–¥–∞–µ—Ç—Å—è)',
                                                'discrepancy_type': '–û–ø–∏—Å–∞–Ω–∏–µ'
                                            }
                                        )
                                
                                # Export option
                                export_label = "üì• –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ Excel" if show_all_matches else "üì• –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è –≤ Excel"
                                
                                if st.button(export_label):
                                    try:
                                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                                        prefix = "category_analysis" if show_all_matches else "category_discrepancies"
                                        filename = f"{prefix}_{timestamp}.xlsx"
                                        results_df.to_excel(filename, index=False)
                                        
                                        with open(filename, "rb") as file:
                                            st.download_button(
                                                label="–°–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª Excel",
                                                data=file.read(),
                                                file_name=filename,
                                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                            )
                                    except Exception as e:
                                        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ: {e}")
                    
                    except Exception as e:
                        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {e}")
                        st.error("–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –æ–±–Ω–æ–≤–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É")
                    
                    finally:
                        # Close the analysis connection
                        if analysis_conn:
                            analysis_conn.close()

with tab2:
    st.header("–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è–º–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
    
    # Quick statistics
    wb_categories = get_unique_wb_categories(conn)
    oz_categories = get_unique_oz_categories(conn)
    mappings_df = get_category_mappings(conn)
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("–ö–∞—Ç–µ–≥–æ—Ä–∏–π WB", len(wb_categories))
    with col2:
        st.metric("–ö–∞—Ç–µ–≥–æ—Ä–∏–π Ozon", len(oz_categories))
    with col3:
        st.metric("–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π", len(mappings_df))
    
    # Tabs for different management options
    mgmt_tab1, mgmt_tab2, mgmt_tab3, mgmt_tab4 = st.tabs([
        "‚ûï –î–æ–±–∞–≤–∏—Ç—å", "üîç –ê–≤—Ç–æ–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è", "üìã –ü—Ä–æ—Å–º–æ—Ç—Ä", "üì§ –ò–º–ø–æ—Ä—Ç/–≠–∫—Å–ø–æ—Ä—Ç"
    ])
    
    with mgmt_tab1:
        st.subheader("–î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏—é WB:**")
            if wb_categories:
                new_wb_category = st.selectbox(
                    "–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö:",
                    [""] + wb_categories,
                    key="select_wb_cat"
                )
            else:
                st.info("–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ WB –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")
                new_wb_category = ""
            
            # Alternative text input
            custom_wb_category = st.text_input(
                "–ò–ª–∏ –≤–≤–µ–¥–∏—Ç–µ –≤—Ä—É—á–Ω—É—é:",
                key="custom_wb_cat",
                help="–ï—Å–ª–∏ –Ω—É–∂–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–µ—Ç –≤ —Å–ø–∏—Å–∫–µ"
            )
            
            final_wb_category = custom_wb_category if custom_wb_category.strip() else new_wb_category
        
        with col2:
            st.write("**–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏—é Ozon:**")
            if oz_categories:
                new_oz_category = st.selectbox(
                    "–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö:",
                    [""] + oz_categories,
                    key="select_oz_cat"
                )
            else:
                st.info("–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ Ozon –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")
                new_oz_category = ""
            
            # Alternative text input
            custom_oz_category = st.text_input(
                "–ò–ª–∏ –≤–≤–µ–¥–∏—Ç–µ –≤—Ä—É—á–Ω—É—é:",
                key="custom_oz_cat",
                help="–ï—Å–ª–∏ –Ω—É–∂–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–µ—Ç –≤ —Å–ø–∏—Å–∫–µ"
            )
            
            final_oz_category = custom_oz_category if custom_oz_category.strip() else new_oz_category
        
        # Notes field
        mapping_notes = st.text_area(
            "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):",
            key="mapping_notes",
            help="–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏"
        )
        
        # Validation
        if final_wb_category and final_oz_category:
            validation = validate_category_mapping(conn, final_wb_category, final_oz_category)
            
            if validation['warnings']:
                for warning in validation['warnings']:
                    st.warning(warning)
            
            if validation['wb_exists'] and validation['oz_exists']:
                st.success(f"‚úÖ –û–±–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–∞–π–¥–µ–Ω—ã –≤ –ë–î (WB: {validation['wb_product_count']} —Ç–æ–≤–∞—Ä–æ–≤, Ozon: {validation['oz_product_count']} —Ç–æ–≤–∞—Ä–æ–≤)")
        
        # Add button
        if st.button("–î–æ–±–∞–≤–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ", type="primary", key="add_mapping"):
            if final_wb_category.strip() and final_oz_category.strip():
                if add_category_mapping(conn, final_wb_category.strip(), final_oz_category.strip(), mapping_notes.strip()):
                    st.rerun()
            else:
                st.warning("–ó–∞–ø–æ–ª–Ω–∏—Ç–µ –æ–±–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏")
    
    with mgmt_tab2:
        st.subheader("–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è")
        st.info("–°–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –≤–æ–∑–º–æ–∂–Ω—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ö–æ–¥—Å—Ç–≤–∞ —Ç–µ–∫—Å—Ç–∞")
        
        similarity_threshold = st.slider(
            "–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ:",
            min_value=0.5,
            max_value=1.0,
            value=0.7,
            step=0.05,
            help="–ß–µ–º –≤—ã—à–µ –∑–Ω–∞—á–µ–Ω–∏–µ, —Ç–µ–º –±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏–º–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞–∑–≤–∞–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π"
        )
        
        if st.button("üîç –ù–∞–π—Ç–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è", key="find_suggestions"):
            with st.spinner("–ê–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏ –ø–æ–∏—Å–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π..."):
                suggestions = suggest_category_mappings(conn, similarity_threshold)
                
                if suggestions:
                    st.success(f"–ù–∞–π–¥–µ–Ω–æ {len(suggestions)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")
                    
                    suggestions_df = pd.DataFrame(suggestions)
                    
                    st.dataframe(
                        suggestions_df,
                        use_container_width=True,
                        hide_index=True,
                        column_config={
                            'wb_category': '–ö–∞—Ç–µ–≥–æ—Ä–∏—è WB',
                            'oz_category': '–ö–∞—Ç–µ–≥–æ—Ä–∏—è Ozon',
                            'similarity': st.column_config.NumberColumn(
                                '–°—Ö–æ–¥—Å—Ç–≤–æ',
                                format="%.2f"
                            ),
                            'confidence': '–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å'
                        }
                    )
                    
                    # Quick add options
                    st.subheader("–ë—ã—Å—Ç—Ä–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ")
                    st.info("–û—Ç–º–µ—Ç—å—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ —Ö–æ—Ç–∏—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å:")
                    
                    selected_suggestions = []
                    for idx, suggestion in enumerate(suggestions):
                        if suggestion['confidence'] in ['High', 'Medium']:  # Only show high/medium confidence
                            col1, col2 = st.columns([1, 4])
                            with col1:
                                if st.checkbox("", key=f"suggest_{idx}"):
                                    selected_suggestions.append(suggestion)
                            with col2:
                                st.write(f"**{suggestion['wb_category']}** ‚Üî **{suggestion['oz_category']}** (—Å—Ö–æ–¥—Å—Ç–≤–æ: {suggestion['similarity']:.2f})")
                    
                    if selected_suggestions:
                        if st.button("‚ûï –î–æ–±–∞–≤–∏—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è", key="add_selected"):
                            success_count = 0
                            for suggestion in selected_suggestions:
                                if add_category_mapping(conn, suggestion['wb_category'], suggestion['oz_category'], f"–ê–≤—Ç–æ–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ (—Å—Ö–æ–¥—Å—Ç–≤–æ: {suggestion['similarity']:.2f})"):
                                    success_count += 1
                            
                            if success_count > 0:
                                st.success(f"–î–æ–±–∞–≤–ª–µ–Ω–æ {success_count} —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π")
                                st.rerun()
                else:
                    st.info("–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–º–µ–Ω—å—à–∏—Ç—å –ø–æ—Ä–æ–≥ —Å—Ö–æ–¥—Å—Ç–≤–∞.")
    
    with mgmt_tab3:
        st.subheader("–°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è")
        
        if mappings_df.empty:
            st.info("–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π –µ—â–µ –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω—ã")
        else:
            # Search and filter
            search_term = st.text_input(
                "üîç –ü–æ–∏—Å–∫ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:",
                help="–í–≤–µ–¥–∏—Ç–µ —á–∞—Å—Ç—å –Ω–∞–∑–≤–∞–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ WB –∏–ª–∏ Ozon"
            )
            
            if search_term:
                filtered_df = mappings_df[
                    mappings_df['wb_category'].str.contains(search_term, case=False, na=False) |
                    mappings_df['oz_category'].str.contains(search_term, case=False, na=False)
                ]
            else:
                filtered_df = mappings_df
            
            st.write(f"–ü–æ–∫–∞–∑–∞–Ω–æ: {len(filtered_df)} –∏–∑ {len(mappings_df)} —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π")
            
            # Display mappings with delete option
            for idx, row in filtered_df.iterrows():
                with st.container():
                    col1, col2, col3, col4, col5 = st.columns([3, 1, 3, 3, 1])
                    
                    with col1:
                        st.text(row['wb_category'])
                    
                    with col2:
                        st.text("‚Üî")
                        
                    with col3:
                        st.text(row['oz_category'])
                    
                    with col4:
                        if row['notes']:
                            st.caption(f"üí¨ {row['notes']}")
                    
                    with col5:
                        if st.button("üóëÔ∏è", key=f"delete_{row['id']}", help="–£–¥–∞–ª–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ"):
                            if delete_category_mapping(conn, row['id']):
                                st.rerun()
                    
                    st.divider()
    
    with mgmt_tab4:
        st.subheader("–ò–º–ø–æ—Ä—Ç –∏ —ç–∫—Å–ø–æ—Ä—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π")
        
        # Export section
        st.write("**üì• –≠–∫—Å–ø–æ—Ä—Ç**")
        col1, col2 = st.columns(2)
        
        with col1:
            include_stats = st.checkbox("–í–∫–ª—é—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ç–æ–≤–∞—Ä–∞–º", value=True)
        
        with col2:
            if st.button("üì• –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ CSV"):
                csv_content = export_category_mappings_to_csv(conn, include_stats)
                if csv_content:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"category_mappings_{timestamp}.csv"
                    
                    st.download_button(
                        label="–°–∫–∞—á–∞—Ç—å CSV —Ñ–∞–π–ª",
                        data=csv_content,
                        file_name=filename,
                        mime="text/csv"
                    )
        
        st.divider()
        
        # Import section
        st.write("**üì§ –ò–º–ø–æ—Ä—Ç**")
        st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏: wb_category, oz_category, notes (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)")
        
        uploaded_file = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ CSV —Ñ–∞–π–ª:",
            type=['csv'],
            key="bulk_import_csv"
        )
        
        if uploaded_file is not None:
            try:
                import_df = pd.read_csv(uploaded_file)
                
                st.write("**–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö:**")
                st.dataframe(import_df.head(10), use_container_width=True)
                
                required_columns = ['wb_category', 'oz_category']
                missing_columns = [col for col in required_columns if col not in import_df.columns]
                
                if missing_columns:
                    st.error(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {missing_columns}")
                else:
                    st.success("‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞")
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("–°—Ç—Ä–æ–∫ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞", len(import_df))
                    with col2:
                        valid_rows = len(import_df.dropna(subset=required_columns))
                        st.metric("–í–∞–ª–∏–¥–Ω—ã—Ö —Å—Ç—Ä–æ–∫", valid_rows)
                    
                    if st.button("üöÄ –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è"):
                        with st.spinner("–ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö..."):
                            csv_content = uploaded_file.getvalue().decode('utf-8')
                            import_stats = import_category_mappings_from_csv(conn, csv_content)
                            
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫", import_stats['total_rows'])
                            with col2:
                                st.metric("–ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ", import_stats['successful_imports'])
                            with col3:
                                st.metric("–ü—Ä–æ–ø—É—â–µ–Ω–æ (–¥—É–±–ª–∏)", import_stats['skipped_existing'])
                            with col4:
                                st.metric("–û—à–∏–±–æ–∫", import_stats['errors'])
                            
                            if import_stats['successful_imports'] > 0:
                                st.success(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {import_stats['successful_imports']} —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π")
                                st.rerun()
                            else:
                                st.warning("‚ö†Ô∏è –ù–æ–≤—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω—ã")
                        
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
    
with tab3:
    st.header("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞")
    
    mappings_df = get_category_mappings(conn)
    usage_stats = get_category_usage_stats(conn)
    unmapped = get_unmapped_categories(conn)
    
    # Overview metrics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("–í—Å–µ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π", len(mappings_df))
    
    with col2:
        mapped_wb = mappings_df['wb_category'].nunique() if not mappings_df.empty else 0
        total_wb = len(get_unique_wb_categories(conn))
        st.metric("–ü–æ–∫—Ä—ã—Ç–∏–µ WB", f"{mapped_wb}/{total_wb}", 
                 delta=f"{mapped_wb/total_wb*100:.1f}%" if total_wb > 0 else "0%")
    
    with col3:
        mapped_oz = mappings_df['oz_category'].nunique() if not mappings_df.empty else 0
        total_oz = len(get_unique_oz_categories(conn))
        st.metric("–ü–æ–∫—Ä—ã—Ç–∏–µ Ozon", f"{mapped_oz}/{total_oz}",
                 delta=f"{mapped_oz/total_oz*100:.1f}%" if total_oz > 0 else "0%")
    
    with col4:
        unmapped_total = len(unmapped['wb']) + len(unmapped['oz'])
        st.metric("–ù–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö", unmapped_total)
    
    if not mappings_df.empty:
        # Recent additions
        st.subheader("–ù–µ–¥–∞–≤–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è")
        recent_mappings = mappings_df.sort_values('created_at', ascending=False).head(10)
        st.dataframe(
            recent_mappings[['wb_category', 'oz_category', 'created_at']],
            use_container_width=True,
            hide_index=True,
            column_config={
                'wb_category': '–ö–∞—Ç–µ–≥–æ—Ä–∏—è WB',
                'oz_category': '–ö–∞—Ç–µ–≥–æ—Ä–∏—è Ozon',
                'created_at': st.column_config.DatetimeColumn(
                    '–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è',
                    format="DD.MM.YYYY HH:mm"
                )
            }
        )
        
        # Show unmapped categories
        if unmapped['wb'] or unmapped['oz']:
            st.subheader("‚ö†Ô∏è –ù–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write(f"**Wildberries ({len(unmapped['wb'])} –∫–∞—Ç–µ–≥–æ—Ä–∏–π):**")
                if unmapped['wb']:
                    for category in unmapped['wb'][:10]:  # Show first 10
                        st.text(f"‚Ä¢ {category}")
                    if len(unmapped['wb']) > 10:
                        st.caption(f"... –∏ –µ—â–µ {len(unmapped['wb']) - 10} –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
                else:
                    st.success("‚úÖ –í—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ WB —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω—ã")
            
            with col2:
                st.write(f"**Ozon ({len(unmapped['oz'])} –∫–∞—Ç–µ–≥–æ—Ä–∏–π):**")
                if unmapped['oz']:
                    for category in unmapped['oz'][:10]:  # Show first 10
                        st.text(f"‚Ä¢ {category}")
                    if len(unmapped['oz']) > 10:
                        st.caption(f"... –∏ –µ—â–µ {len(unmapped['oz']) - 10} –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
                else:
                    st.success("‚úÖ –í—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ Ozon —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω—ã")
        
        # Category usage statistics
        if not usage_stats['wb'].empty or not usage_stats['oz'].empty:
            st.subheader("üìà –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
            
            col1, col2 = st.columns(2)
            
            with col1:
                if not usage_stats['wb'].empty:
                    st.write("**–¢–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ WB –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Ç–æ–≤–∞—Ä–æ–≤:**")
                    wb_top = usage_stats['wb'].head(10)
                    st.dataframe(
                        wb_top[['wb_category', 'unique_skus']],
                        use_container_width=True,
                        hide_index=True,
                        column_config={
                            'wb_category': '–ö–∞—Ç–µ–≥–æ—Ä–∏—è',
                            'unique_skus': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ SKU'
                        }
                    )
            
            with col2:
                if not usage_stats['oz'].empty:
                    st.write("**–¢–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ Ozon –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Ç–æ–≤–∞—Ä–æ–≤:**")
                    oz_top = usage_stats['oz'].head(10)
                    st.dataframe(
                        oz_top[['oz_category', 'unique_skus']],
                        use_container_width=True,
                        hide_index=True,
                        column_config={
                            'oz_category': '–ö–∞—Ç–µ–≥–æ—Ä–∏—è',
                            'unique_skus': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ SKU'
                        }
                    )
    else:
        st.info("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–∞ –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π –∫–∞—Ç–µ–≥–æ—Ä–∏–π")

# Connection will be closed automatically when the script ends
# No need to explicitly close it as it may interfere with cached operations 